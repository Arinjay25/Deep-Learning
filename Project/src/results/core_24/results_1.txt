filename log/doomrnn.cma.16.24.best.json
model size 1088
making real doom environment
2018-07-21 03:25:17.010713: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
model using cpu
input dropout mode = False
output dropout mode = False
recurrent dropout mode = False
GLib-GIO-Message: 03:25:22.465: Using the 'memory' GSettings backend.  Your settings will not be saved or shared with other applications.
loading file log/doomrnn.cma.16.24.best.json
iteration 0 reward 592.0
iteration 1 reward 1536.0
iteration 2 reward 576.0
iteration 3 reward 575.0
iteration 4 reward 456.0
iteration 5 reward 1164.0
iteration 6 reward 1430.0
iteration 7 reward 2100.0
iteration 8 reward 1043.0
iteration 9 reward 1524.0
iteration 10 reward 934.0
iteration 11 reward 2100.0
iteration 12 reward 2100.0
iteration 13 reward 1292.0
iteration 14 reward 222.0
iteration 15 reward 589.0
iteration 16 reward 717.0
iteration 17 reward 2031.0
iteration 18 reward 237.0
iteration 19 reward 1647.0
iteration 20 reward 479.0
iteration 21 reward 216.0
iteration 22 reward 595.0
iteration 23 reward 1414.0
iteration 24 reward 807.0
iteration 25 reward 594.0
iteration 26 reward 2100.0
iteration 27 reward 1046.0
iteration 28 reward 948.0
iteration 29 reward 1645.0
iteration 30 reward 1526.0
iteration 31 reward 478.0
iteration 32 reward 693.0
iteration 33 reward 446.0
iteration 34 reward 1322.0
iteration 35 reward 1531.0
iteration 36 reward 702.0
iteration 37 reward 685.0
iteration 38 reward 1425.0
iteration 39 reward 1068.0
iteration 40 reward 571.0
iteration 41 reward 1162.0
iteration 42 reward 578.0
iteration 43 reward 1526.0
iteration 44 reward 331.0
iteration 45 reward 223.0
iteration 46 reward 340.0
iteration 47 reward 459.0
iteration 48 reward 832.0
iteration 49 reward 107.0
iteration 50 reward 349.0
iteration 51 reward 831.0
iteration 52 reward 1534.0
iteration 53 reward 218.0
iteration 54 reward 747.0
iteration 55 reward 954.0
iteration 56 reward 561.0
iteration 57 reward 1471.0
iteration 58 reward 1520.0
iteration 59 reward 713.0
iteration 60 reward 708.0
iteration 61 reward 1045.0
iteration 62 reward 814.0
iteration 63 reward 815.0
iteration 64 reward 223.0
iteration 65 reward 1094.0
iteration 66 reward 336.0
iteration 67 reward 346.0
iteration 68 reward 576.0
iteration 69 reward 822.0
iteration 70 reward 224.0
iteration 71 reward 687.0
iteration 72 reward 698.0
iteration 73 reward 1647.0
iteration 74 reward 694.0
iteration 75 reward 209.0
iteration 76 reward 950.0
iteration 77 reward 208.0
iteration 78 reward 1188.0
iteration 79 reward 896.0
iteration 80 reward 1294.0
iteration 81 reward 837.0
iteration 82 reward 222.0
iteration 83 reward 1058.0
iteration 84 reward 571.0
iteration 85 reward 696.0
iteration 86 reward 2011.0
iteration 87 reward 333.0
iteration 88 reward 2100.0
iteration 89 reward 456.0
iteration 90 reward 833.0
iteration 91 reward 220.0
iteration 92 reward 107.0
iteration 93 reward 699.0
iteration 94 reward 829.0
iteration 95 reward 1418.0
iteration 96 reward 453.0
iteration 97 reward 569.0
iteration 98 reward 93.0
iteration 99 reward 1302.0
seed 7710 average_reward 878.93 stdev 534.2170767581283
